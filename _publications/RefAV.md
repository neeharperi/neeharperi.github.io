---
title: 'RefAV: Towards Planning-Centric Scenario Mining'
collection: publications
permalink: /publications/RefAV
excerpt: ''
date: 2026-02-01
venue: 'CVPR'
paperurl: ''
citation: 'Davidson C, Ramanan D, Peri N. RefAV: Towards Planning-Centric Scenario Mining. In: Conference on Computer Vision and Patern Recognition, CVPR 2026'

---

Autonomous Vehicles (AVs) collect and pseudo-label terabytes of multi-modal data localized to HD maps during normal fleet testing. However, identifying interesting and safety-critical scenarios from uncurated driving logs remains a significant challenge. Traditional scenario mining techniques are error-prone and prohibitively time-consuming, often relying on hand-crafted structured queries. In this work, we revisit spatio-temporal scenario mining through the lens of recent vision-language models (VLMs) to detect whether a described scenario occurs in a driving log and, if so, precisely localize it in both time and space. To address this problem, we introduce RefAV, a large-scale dataset of 10,000 diverse natural language queries that describe complex multi-agent interactions relevant to motion planning derived from 1000 driving logs in the Argoverse 2 Sensor dataset. We evaluate several referential multi-object trackers and present an empirical analysis of our baselines. Notably, we find that naively repurposing off-the-shelf VLMs yields poor performance, suggesting that scenario mining presents unique challenges. Lastly, we discuss our recently held competition and share insights from the community.

[[Download Paper](https://neeharperi.com/files/RefAV.pdf)]
[[Code](https://github.com/CainanD/RefAV)]
